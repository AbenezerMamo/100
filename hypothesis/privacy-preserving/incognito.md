# A way to push ML models forward that's privacy, future self maxima, and social welfare function

Google Maps and Browsers have incognito modes that ought to beg the question: "am I just evading the search history log or looking to escape diluting the precious ML models that define my recommendations?"

### Proposed solution
The duality to consider is that recommendation models being classified and segmented inherently requires that you accept the trade-off risk from actually labeling them, the cultural impact of labeling them, and the echo-chamber it will create if you use one over another. Sometimes, the inherent beauty is in actually allowing the DJ to play the music. Though, I would imagine it'd be useful for my Spotify so I can get the best "Auto playlists" made. For YouTube, maybe I need inspiration to sample from another interest. For school and work, I imagine it would be really useful. Though always important to design for "fun" but making it desirable enough to build skill mastery gifts longevity.

Sometimes, it's important to correct when I change my mind or I realize I was maybe just wrong. Sometimes, explaining why the delta makes me uncomfortable is what's needed.

Let's live a life that's worth looking back on and sometimes that's okay to just put into another box. The promises you make to yourself are what define you. To do that, tools have to give us more and more autonomy as suggested by service design UX & high performance US aviation design research on Auto-pilot to human relationship. The most elegant DAPP for crypto to onboard is just a promise to ourselves that's privacy protected. This could be a savings account, a PII safe birthday digital card, or commitments publicly made that cost exponentially growing cost to fund on the blockchain. That way, you put money where your grit is; hopefully with collective maxima and not risking capital on chances that you're not willing to pay more for continuously.
